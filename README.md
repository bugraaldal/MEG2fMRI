# MEG2fMRI
### Abstract
Combining hemodynamic and electrophysiological neuroimaging techniques provides a strong window into the spatiotemporal dynamics of brain activity. Direct data fusion is severely hampered by the differences between magnetoencephalography and functional magnetic resonance imaging, particularly with regard to resolution, dimensionality, and acquisition timing. In this study, we introduce a new deep learning approach for creating functional magnetic resonance imaging slices from magnetoencephalography signals using a conditional generative adversarial network. In order to create 32Ã—32 functional magnetic resonance imaging slices, we converted magnetoencephalography epochs into low-dimensional embeddings and trained a Pix2Pix-style generative adverserial network on aligned magnetoencephalography and functional magnetic resonance imaging event pairs. Mean squared error and structural similarity index were used to assess our model. On held-out data, we obtained a mean squared error of 0.046 and structural similarity index of 0.622. Our results show the viability of magnetoencephalography-to-functional-magnetic-resonance-imaging synthesis and highlight the expanding potential of synthetic neuroimaging data, despite obstacles such as data alignmnt, computing limitations, and training instability. We suggest a number of potential options, such as time-series modeling, 3D or 4D volumetric and timed pipelines, better alignment via unsupervised learning, and postprocessing for higher-quality images. This work serves as a proof-of-concept for deep generative models that are being developed for data augmentation and cross-modal neuroimaging translation.
